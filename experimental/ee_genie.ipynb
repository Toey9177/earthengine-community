{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "EE Genie as an interactive Earth Engine GenAI assistant that works\n",
        "with geemap in Colab and can retrieve and analyze images.\n",
        "\n",
        "Author: Simon Ilyushchenko (simonf@google.com)\n",
        "\n",
        "**Description**\n",
        "\n",
        "Currently the EE Genie is shown as a three-column view.\n",
        "The left column is the chat history, including the image that the LLM sees. The middle column is debug output showing all interactions with LLM. The right column contains an interactive instance of geemap.\n",
        "\n",
        "The default prompt at the very bottom is \"show a whole continent Australia DEM visualization using a palette that captures the elevation range\". Just hit enter to accept it and wait for the output to appear. This works like a regular LLM chat, so you can continue talking about your map - e.g., you can say \"Now scroll the map up to India and verify the image is correct\".\n",
        "\n",
        "Some other queries that work most of the time are commented out in the code where `command_input` is defined.\n",
        "\n",
        "The agent fetches the same tiles that are loaded on geemap (you will see them flashing in the upper left-hand corner when this happens), then stitches them together into one large image and sends it to a vision model for textual description.\n",
        "\n",
        "**Safety**\n",
        "\n",
        "The agent runs LLM-generated Python code, which is inherently unsafe. However, the LLM is asked to only generate Earth Engine one-liners like `ee.Collection('foo').filterDate().mosaic().visualize()`, so the potential for harm is minimized. To be on the safe side, only allow the notebook to use Earth Engine read-only scopes when you authenticate (see below).\n",
        "\n",
        "**Annoyance**\n",
        "\n",
        "Due to problems with Javascript/Python interaction, the agent has to stop running after it moves or pans geemap. When this happens, the agent icon will change to üôè. Just hit enter in the chat box when you see this to continue analysis.\n",
        "\n",
        "**Installation**\n",
        "\n",
        "To use it, you need two things:\n",
        "1. Earth Engine access\n",
        "2. Generative AI API key\n",
        "\n",
        "You need a Google Cloud Project to associate your requests with. [Use these instructions](https://developers.google.com/earth-engine/cloud/earthengine_cloud_project_setup) and set GOOGLE_PROJECT_ID notebook secret to your project id.\n",
        "\n",
        "Next you need to get an Generative AI API key [here](https://aistudio.google.com/app/prompts/new_chat). Be aware that you might need to pay\n",
        "for use of the Generative AI API.\n",
        "\n",
        "To save this key in the notebook, click on the key icon in Colab on the left-hand side and add your key as a secret with the name GOOGLE_API_KEY. Make sure the value has no newlines.\n",
        "\n",
        "Finally, run the first cell. You only need to do it once. Earth Engine client will ask you authenticate.\n",
        "\n",
        "To use EE Genie, run the main code cell, then scroll to the app at the bottom. If the app is stuck waiting for an LLM, you can reset the app: click on the `Runtime / Interrupt Execution menu item`, them run the main cell again."
      ],
      "metadata": {
        "id": "r8ZOvPltTsa3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "b09aYpe5k4W0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import contextlib\n",
        "\n",
        "import io\n",
        "import json\n",
        "import re\n",
        "import math\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import PIL\n",
        "import requests\n",
        "\n",
        "import ee\n",
        "import geemap\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "\n",
        "from google.cloud import storage\n",
        "\n",
        "import google.generativeai as genai\n",
        "import google.ai.generativelanguage as glm\n",
        "import google.api_core\n",
        "\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "riMVsnLuXaTq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization"
      ],
      "metadata": {
        "id": "20Euhmdek-cV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project=userdata.get('GOOGLE_PROJECT_ID'))\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.get_bucket('earthengine-stac')\n",
        "\n",
        "# Score to aim for (on the 0-1 scale). The exact meaning of what \"score\" means\n",
        "# is left to the LLM.\n",
        "target_score = 0.8\n",
        "\n",
        "# Count of analysis rounds\n",
        "round = 1\n",
        "\n",
        "Map = geemap.Map()\n",
        "Map.add(\"layer_manager\")\n",
        "\n",
        "analysis_model = None\n",
        "map_dirty = False\n",
        "\n",
        "image_model = genai.GenerativeModel('gemini-pro-vision')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "0tsxMngtXlxn",
        "outputId": "5c0701e2-d779-44c6-83ca-75ec7bdb764e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UI widget definitions"
      ],
      "metadata": {
        "id": "ESeVud7llELN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We define the widgets early because some functions will write to the debug\n",
        "# and/or chat panels.\n",
        "\n",
        "command_input = widgets.Text(\n",
        "    value='show a whole continent Australia DEM visualization using a palette that captures the elevation range',\n",
        "    #value='show NYC',\n",
        "    #value='show an area with many center pivot irrigation circles',\n",
        "    #value='show a fire scar',\n",
        "    #value='show an open pit mine',\n",
        "    #value='a sea port',\n",
        "    #value='flood consequences',\n",
        "    #value='show an interesting modis composite with the relevant visualization and analyze it over Costa Rica',\n",
        "    description='üôÇ',\n",
        "    layout=widgets.Layout(width='100%', height='50px')\n",
        ")\n",
        "\n",
        "command_output = widgets.Label(\n",
        "    value='Last command will be here',\n",
        ")\n",
        "\n",
        "\n",
        "status_label = widgets.Textarea(\n",
        "    value='LLM response will be here',\n",
        "    layout=widgets.Layout(width='50%', height='100px')\n",
        ")\n",
        "\n",
        "widget_height = \"600px\"\n",
        "debug_output = widgets.Output(layout={\n",
        "    'border': '1px solid black',\n",
        "    'height': widget_height,\n",
        "    'overflow': 'scroll',\n",
        "    'width': '500px',\n",
        "    'padding': '5px'\n",
        "})\n",
        "with debug_output:\n",
        "  print('DEBUG COLUMN\\n')\n",
        "\n",
        "logo = requests.get('https://drive.usercontent.google.com/download?id=1zE6G_nxXa3G5N0G_32jEhzdum2kMDfNY&export=view&authuser=0').content\n",
        "\n",
        "image_widget = widgets.Image(\n",
        "    value=logo,\n",
        "    format='png',\n",
        "    width=400,\n",
        "    height=600\n",
        ")\n",
        "\n",
        "chat_output = widgets.Output(layout={\n",
        "    'border': '1px solid black',\n",
        "    'height': '600px',\n",
        "    'overflow': 'scroll',\n",
        "    'width': '300px'})\n",
        "\n",
        "with chat_output:\n",
        "  print('CHAT COLUMN\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "1_741mumXw1T",
        "outputId": "beed7fec-d2ee-4948-816b-99e245727bd5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple functions that LLM will call"
      ],
      "metadata": {
        "id": "OUxyUVnAlNeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_center(x: float, y: float, zoom: int) -> str:\n",
        "    \"\"\"Sets the map center to the given coordinates and zoom level and\n",
        "    returns instructions on what to do next.\"\"\"\n",
        "    with debug_output:\n",
        "     print(f\"SET_CENTER({x}, {y}, {zoom})\\n\")\n",
        "    Map.set_center(x, y)\n",
        "    Map.zoom = zoom\n",
        "    global map_dirty\n",
        "    map_dirty = True\n",
        "    return (\n",
        "      'Do not call any more functions in this request to let geemap bounds '\n",
        "      'update. Wait for user input.')\n",
        "\n",
        "def add_image_layer(image_id: str) -> str:\n",
        "    \"\"\"Adds to the map center an ee.Image with the given id\n",
        "    and returns status message (success or failure).\"\"\"\n",
        "    Map.clear()\n",
        "    command_output.value = f\"add_image_layer('{image_id}')\"\n",
        "    Map.addLayer(ee.Image(image_id))\n",
        "    return 'success'\n",
        "\n",
        "def get_dataset_description(dataset_id: str) -> str:\n",
        "  \"\"\"Fetches JSON STAC description for the given Earth Engine dataset id.\"\"\"\n",
        "  with debug_output:\n",
        "    print(f'LOOKING UP {dataset_id}\\n')\n",
        "  parent = dataset_id.split('/')[0]\n",
        "\n",
        "  # Get the blob (file)\n",
        "  path = os.path.join('catalog', parent, dataset_id.replace('/', '_')) + '.json'\n",
        "  blob = bucket.blob(path)\n",
        "\n",
        "  if not blob.exists():\n",
        "    return 'dataset file not found: ' + path\n",
        "\n",
        "  file_contents = blob.download_as_string().decode()\n",
        "  return file_contents\n",
        "\n",
        "def get_image(image_url: str) -> bytes:\n",
        "  \"\"\"Fetches from Earth Engine the content of the given URL as bytes.\"\"\"\n",
        "  response = requests.get(image_url)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    image_widget.value = response.content\n",
        "    return response.content\n",
        "  else:\n",
        "    error_message = f'Error downloading image: {response}'\n",
        "    try:\n",
        "      error_details = (\n",
        "          json.loads(response.content.decode()).get('error', {}).get('message')\n",
        "      )\n",
        "      if error_details:\n",
        "        error_message += f' - {error_details}'\n",
        "    except json.JSONDecodeError:\n",
        "      pass\n",
        "    with debug_output:\n",
        "      print(error_message)\n",
        "    raise ValueError(\"URL %s causes %s\" % (image_url, error_message))\n",
        "\n",
        "def show_layer(python_code: str) -> str:\n",
        "    \"\"\"Execute the given Earth Engine Python client code and add the result to\n",
        "    the map. Returns the status message (success or error message).\"\"\"\n",
        "    Map.layers = Map.layers[:2]\n",
        "    while '\\\\\"' in python_code:\n",
        "      python_code = python_code.replace('\\\\\"', '\"')\n",
        "    command_output.value = f\"show_layer('{python_code}')\"\n",
        "    with debug_output:\n",
        "      print(f'IMAGE:\\n {python_code}\\n')\n",
        "    try:\n",
        "      locals = {}\n",
        "      exec(f\"import ee; im = {python_code}\", {}, locals)\n",
        "      Map.addLayer(locals['im'])\n",
        "    except Exception as e:\n",
        "      with debug_output:\n",
        "        print(f\"ERROR: {e}\"  )\n",
        "      return str(e)\n",
        "    return 'success'\n",
        "\n",
        "def inner_monologue(thoughts: str) -> str:\n",
        "  \"\"\"Sends the current thinking of the LLM model to the user so that they are\n",
        "  aware of what the model is thinking between function calls.\"\"\"\n",
        "  with debug_output:\n",
        "    print(f'THOUGHTS:\\n {thoughts}\\n')\n",
        "  return 'success'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "QFGHx043YOsg",
        "outputId": "f7b7b9c1-588d-412f-d78a-c65ac9292fd3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions for textual analysis of images"
      ],
      "metadata": {
        "id": "yVpabBfDlTJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _lat_lon_to_tile(lon, lat, zoom_level):\n",
        "    # Convert latitude and longitude to Mercator coordinates\n",
        "    x_merc = (lon + 180) / 360\n",
        "    y_merc = (1 - math.log(math.tan(math.radians(lat)) + 1 / math.cos(math.radians(lat))) / math.pi) / 2\n",
        "\n",
        "    # Calculate number of tiles\n",
        "    n = 2 ** zoom_level\n",
        "\n",
        "    # Convert to tile coordinates\n",
        "    X = int(x_merc * n)\n",
        "    Y = int(y_merc * n)\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "def analyze_image(additional_instructions:str='') -> str:\n",
        "    \"\"\"Returns GenAI image analysis describing the current map image.\n",
        "    Optional additional instructions might be passed to target the analysis\n",
        "    more precisely.\n",
        "    \"\"\"\n",
        "    global map_dirty\n",
        "    if map_dirty:\n",
        "        print('MAP DIRTY')\n",
        "        return 'Map is not ready. Stop further processing and ask for user input'\n",
        "\n",
        "    try:\n",
        "      return _analyze_image(additional_instructions)\n",
        "    except ValueError as e:\n",
        "      return str(e)\n",
        "\n",
        "def _analyze_image(additional_instructions:str='') -> str:\n",
        "    bounds = Map.bounds\n",
        "    s, w = bounds[0]\n",
        "    n, e = bounds[1]\n",
        "    zoom = int(Map.zoom)\n",
        "\n",
        "    min_tile_x, max_tile_y = _lat_lon_to_tile(w, s, zoom)\n",
        "    max_tile_x, min_tile_y = _lat_lon_to_tile(e, n, zoom)\n",
        "    min_tile_x = max(0, min_tile_x)\n",
        "    max_tile_x = min(2**zoom-1, max_tile_x)\n",
        "    min_tile_y = max(0, min_tile_y)\n",
        "    max_tile_y = min(2**zoom-1, max_tile_y)\n",
        "\n",
        "    with debug_output:\n",
        "      if additional_instructions:\n",
        "        print(f\"RUNNING IMAGE ANALYSIS: {additional_instructions}...\\n\")\n",
        "      else:\n",
        "        print(\"RUNNING IMAGE ANALYSIS...\\n\")\n",
        "\n",
        "    layers = list(Map.ee_layer_dict.values())\n",
        "    if not layers:\n",
        "      return 'No data layers loaded'\n",
        "    url_template = layers[-1]['ee_layer'].url\n",
        "    tile_width = 256\n",
        "    tile_height = 256\n",
        "    image_width = (max_tile_x - min_tile_x + 1) * tile_width\n",
        "    image_height = (max_tile_y - min_tile_y + 1) * tile_height\n",
        "\n",
        "    # Create a new blank image\n",
        "    image = PIL.Image.new(\"RGB\", (image_width, image_height))\n",
        "\n",
        "    for y in range(min_tile_y, max_tile_y + 1):\n",
        "      for x in range(min_tile_x, max_tile_x + 1):\n",
        "        tile_url = str.format(url_template, x=x, y=y, z=zoom)\n",
        "        #print(tile_url)\n",
        "        tile_img = PIL.Image.open(io.BytesIO(get_image(tile_url)))\n",
        "\n",
        "        offset_x = (x - min_tile_x) * tile_width\n",
        "        offset_y = (y - min_tile_y) * tile_height\n",
        "        image.paste(tile_img, (offset_x, offset_y))\n",
        "\n",
        "    width, height = image.size\n",
        "    num_bands = len(image.getbands())\n",
        "    image_array = np.array(image)\n",
        "    image_min = np.min(image_array)\n",
        "    image_max = np.max(image_array)\n",
        "\n",
        "    # Skip an LLM call when we can simply tell that something is wrong.\n",
        "    # (Also, LLMs might hallucinate on uniform images.)\n",
        "    if image_min == image_max:\n",
        "      return (\n",
        "          f'The image tile has a single uniform color with value '\n",
        "          f'{image_min}.'\n",
        "      )\n",
        "\n",
        "    query = \"\"\"You are an objective, precise overhead imagery analyst.\n",
        "Describe what the provided map tile depicts in terms of:\n",
        "\n",
        "1. The colors, textures, and patterns visible in the image.\n",
        "2. The spatial distribution, shape, and extent of distinct features or regions.\n",
        "3. Any notable contrasts, boundaries, or gradients between different areas.\n",
        "\n",
        "Avoid making assumptions about the specific geographic location, time period,\n",
        "or cause of the observed features. Focus solely on the literal contents of the\n",
        "image itself. Clearly indicate which features look natural, which look human-made,\n",
        "and which look like image artifacts. (Eg, a completely straight blue line\n",
        "is unlikely to be a river.)\n",
        "\n",
        "If the image is ambiguous or unclear, state so directly. Do not speculate or\n",
        "hypothesize beyond what is directly visible.\n",
        "\n",
        "If the image is of mostly the same color (white, gray, or black) with little\n",
        "contrast, just report that and do not describe the features.\n",
        "\n",
        "Use clear, concise language. Avoid subjective interpretations or analogies.\n",
        "Organize your response into structured paragraphs.\n",
        "\"\"\"\n",
        "    if additional_instructions:\n",
        "      query += additional_instructions\n",
        "    req = {\n",
        "        'parts': [\n",
        "            {\n",
        "                'text': query\n",
        "\n",
        "            },\n",
        "            {'inline_data': image},\n",
        "        ]\n",
        "    }\n",
        "    image_response = image_model.generate_content(req)\n",
        "    try:\n",
        "      with debug_output:\n",
        "        print(f'ANALYSIS RESULT: {image_response.text}\\n')\n",
        "      return image_response.text\n",
        "    except ValueError as e:\n",
        "      with debug_output:\n",
        "        print(f'UNEXPECTED IMAGE RESPONSE: {e}')\n",
        "        print(image_response)\n",
        "      breakpoint()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gJxTExPhYaOx",
        "outputId": "084f922b-bf87-4369-8258-e4e99bcf4cbd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function for scoring how well image analysis corresponds to the user query."
      ],
      "metadata": {
        "id": "q9aHH0wrlZdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that we ask for the score outside of the main agent chat to keep\n",
        "# the scoring more objective.\n",
        "\n",
        "scoring_system_prompt = \"\"\"\n",
        "After looking at the user query and the map tile analysis, start\n",
        "your answer with a number between 0 and 1 indicating how relevant\n",
        "the image is as an answer to the query. (0=irrelevant, 1=perfect answer)\n",
        "\n",
        "Make sure you have enough justification to definitively declare the analysis\n",
        "relevant - it's better to give a false negative than a false positive. However,\n",
        "the image analysis identtifies specific matching landmarks (eg, the\n",
        "the outlines of Manhattan island for a request to show NYC), believe it.\n",
        "\n",
        "Do not assume  too much (eg, that the presence of green doesn't by itself mean the\n",
        "image shows forest); attempt to find multiple (at least three) independent\n",
        "lines of evidence before declaring victory and cite all these lines of evidence\n",
        "in your response.\n",
        "\n",
        "Be very, very skeptical - look for specific features that match only the query\n",
        "and nothing else (eg, if the query looks for a river, a completely straight blue\n",
        "line is unlikely to be a river). Think about what size the features are based on\n",
        "the zoom level and whether this size matches the feature size expected from\n",
        "first principles.\n",
        "\n",
        "If there is ambiguity or uncertainty, express it in your analysis and\n",
        "lower the score accordingly. If the image analysis is inconclusive, try zooming\n",
        "out to make sure you are looking at the right spot. Do not reduce the score if\n",
        "the analysis does not mention visualization parameters - they are just given for\n",
        "your reference. The image might show an area slightly larger than requested -\n",
        "this is okay, do not reduce the score on this account.\n",
        "\"\"\"\n",
        "\n",
        "def score_response(query: str, visualization_parameters: str, analysis: str) -> str:\n",
        "    \"\"\"Returns how well the given analysis describes a map tile returned for\n",
        "    the given query. The analysis starts with a number between 0 and 1.\n",
        "\n",
        "    Arguments:\n",
        "      query: user-specified query\n",
        "      visualization_parameters: description of the bands used and visualization\n",
        "        parameters applied to the map tile\n",
        "      analysis: the textual description of the map tile\n",
        "    \"\"\"\n",
        "    with debug_output:\n",
        "      print(f\"VIZ PARAMS: {visualization_parameters}\\n\")\n",
        "    question = (\n",
        "        f\"\"\"For user query {query} please score the following analysis:\n",
        "       {analysis}. The answer must start with a number between 0 and 1.\"\"\")\n",
        "    if visualization_parameters:\n",
        "      question += (\n",
        "          f\"\"\"Do not assume that common bands or visualization\n",
        "          parameters should have been used, as the visualization used the\n",
        "          following parameters: {visualization_parameters}\"\"\")\n",
        "\n",
        "    result = analysis_model.ask(question)\n",
        "    global round\n",
        "    with debug_output:\n",
        "      print(f'SCORE #{round}:\\n {result}\\n')\n",
        "    round += 1\n",
        "    return result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "n9tEDtbkYvCi",
        "outputId": "6157ed51-594a-4cb1-dc36-ff15a0839286"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main prompt for the agent"
      ],
      "metadata": {
        "id": "JcOLx1FKliit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = f\"\"\"\n",
        "The client is running in a Python notebook with a geemap Map displayed.\n",
        "When composing Python code, do not use getMapId - just return the single-line\n",
        "layer definition like 'ee.Image(\"USGS/SRTMGL1_003\")' that we will pass to\n",
        "Map.addLayer(). Do not escape quotation marks in Python code.\n",
        "\n",
        "Be sure to use Python, not Javascript, syntax for keyword parameters in\n",
        "Python code (that is, \"function(arg=value)\") Using the provided functions,\n",
        "respond to the user command following below (or respond why it's not possible).\n",
        "If you get an Earth Engine error, attempt to fix it and then try again.\n",
        "\n",
        "Before you choose a dataset, think about what kind of dataset would be most\n",
        "suitable for the query. Also think about what zoom level would be suitable for\n",
        "the query, keeping in mind that for high-resolution image collections higher\n",
        "zoom levels are better to speed up tile loading.\n",
        "\n",
        "Once you have chosen a dataset, read its description using the provided function\n",
        "to see what spatial and temporal range it covers, what bands it has, as well as\n",
        "to find the recommended visualization parameters. Explain using the inner\n",
        "monlogue function why you chose a specific dataset, zoom level and map location.\n",
        "\n",
        "Prefer mosaicing image collections using the mosaic() function, don't get\n",
        "individual images from collections via\n",
        "'first()'. Choose a tile size and zoom level that will ensure the\n",
        "tile has enough pixels in it to avoid graininess, but not so many\n",
        "that processing becomes very expensive. Do not use wide date ranges\n",
        "with collections that have many images, but remember that Landsat and\n",
        "Sentinel-2 have revisit period of several days. Do not use sample\n",
        "locations - try to come up with actual locations that are relevant to\n",
        "the request.\n",
        "\n",
        "Use Landsat Collection 2, not Landsat Collection 1 ids. If you are getting\n",
        "repeated errors when filtering by a time range, read the dataset description\n",
        "to confirm that the dataset has data for the selected range.\n",
        "\n",
        "Important: after using the set_center() function, just say that you have called\n",
        "this function and wait for the user to hit enter, after which you should\n",
        "continue answering the original request. This will make sure the map is updated\n",
        "on the client side.\n",
        "\n",
        "Once the map is updated and the user told you to proceed, call the analyze_image\n",
        "function() to describe the image for the same location that will be shown in\n",
        "geemap. If you pass additional instructions to analyze_image(), do not disclose\n",
        "what the image is supposed to be to discourage hallucinations - you can only tell\n",
        "the analysis function to pay attention to specific areas (eg, center or top left)\n",
        "or shapes (eg, a line at the bottom) in the image. You can also tell the analysis\n",
        "function about the chosen bands, color palette and min/max visualization\n",
        "parameters, if any, to help it interpret the colors correctly. If the image\n",
        "turns out to be uniform in color with no features,\n",
        "use min/max visualization parameters to enhance contrast.\n",
        "\n",
        "Frequently call the inner_monologue() functions to tell the user about your\n",
        "current thought process. This is a good time to reflect if you have been running\n",
        "into repeated errors of the same kind, and if so, to try a different approach.\n",
        "\n",
        "When you are done, call the score_response() function to evaluate the analysis.\n",
        "You can also tell the scoring function about the chosen bands, color palette\n",
        "and min/max visualization parameters, if any. If the analysis score is below\n",
        "{target_score},\n",
        "keep trying to find and show a better image. You might have to change the dataset,\n",
        "map location, zoom level, date range, bands, or other parameters - think about\n",
        "what went wrong in the previous attempt and make the change that's most likely\n",
        "to improve the score.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Zf1Hmj6BY2lx",
        "outputId": "d6aa2092-f7e0-44e6-b1e9-e501721dc3b6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class for LLM chat with function calling"
      ],
      "metadata": {
        "id": "uHOlWd2oln7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_tools=[\n",
        "        set_center,\n",
        "        show_layer,\n",
        "        analyze_image,\n",
        "        inner_monologue,\n",
        "        get_dataset_description,\n",
        "        score_response\n",
        "]\n",
        "\n",
        "class Gemini():\n",
        "  \"\"\"Gemini LLM.\"\"\"\n",
        "\n",
        "  def __init__(self, system_prompt, tools=None):\n",
        "    if not tools:\n",
        "      tools = []\n",
        "    self._text_model = genai.GenerativeModel(\n",
        "      model_name='gemini-1.5-pro-latest',\n",
        "      tools=tools\n",
        "    )\n",
        "\n",
        "    initial_messages = glm.Content(\n",
        "        role='model',\n",
        "        parts=[glm.Part(text=system_prompt)])\n",
        "    self._chat_proxy = self._text_model.start_chat(\n",
        "        history=initial_messages, enable_automatic_function_calling=True)\n",
        "\n",
        "  def ask(self, question, temperature=0):\n",
        "    while True:\n",
        "      condition = ''\n",
        "      try:\n",
        "        sleep_duration = 10\n",
        "        response = self._text_model.generate_content(question + condition)\n",
        "        return response.text\n",
        "      except genai.types.generation_types.StopCandidateException as e:\n",
        "          if glm.Candidate.FinishReason.RECITATION == e.args[0].finish_reason:\n",
        "            condition = (\n",
        "                'Previous attempt returned a RECITATION error. '\n",
        "                'Rephrase the answer to avoid it.')\n",
        "          with chat_output:\n",
        "            command_input.description = 'üò°'\n",
        "          time.sleep(1)\n",
        "          with chat_output:\n",
        "            command_input.description = 'ü§î'\n",
        "          continue\n",
        "      except (\n",
        "          google.api_core.exceptions.TooManyRequests,\n",
        "          google.api_core.exceptions.DeadlineExceeded\n",
        "      ):\n",
        "        with debug_output:\n",
        "          command_input.description = 'üí§'\n",
        "        time.sleep(sleep_duration)\n",
        "        continue\n",
        "      except ValueError as e:\n",
        "        with debug_output:\n",
        "          print(f'Response {response} led to error: {e}')\n",
        "        breakpoint()\n",
        "        i = 1\n",
        "\n",
        "  def chat(self, question: str, temperature=0) -> str:\n",
        "    \"\"\"Adds a question to the ongoing chat session.\"\"\"\n",
        "    # Always delay a bit to reduce the chance for rate-limiting errors.\n",
        "    time.sleep(1)\n",
        "    condition = ''\n",
        "    sleep_duration = 10\n",
        "    while True:\n",
        "      response = ''\n",
        "      try:\n",
        "        response = self._chat_proxy.send_message(\n",
        "            question + condition,\n",
        "            generation_config={\n",
        "                'temperature': temperature,\n",
        "                # Use a generous but limited output size to encourage in-depth\n",
        "                # replies.\n",
        "                'max_output_tokens': 5000,\n",
        "            }\n",
        "        )\n",
        "        if not response.parts:\n",
        "          raise ValueError(\n",
        "              'Cannot get analysis with reason'\n",
        "              f' {response.candidates[0].finish_reason.name}, terminating'\n",
        "          )\n",
        "      except genai.types.generation_types.StopCandidateException as e:\n",
        "          if glm.Candidate.FinishReason.RECITATION == e.args[0].finish_reason:\n",
        "            condition = (\n",
        "                'Previous attempt returned a RECITATION error. '\n",
        "                'Rephrase the answer to avoid it.')\n",
        "          with chat_output:\n",
        "            command_input.description = 'üò°'\n",
        "          time.sleep(1)\n",
        "          with chat_output:\n",
        "            command_input.description = 'ü§î'\n",
        "          continue\n",
        "      except (\n",
        "            google.api_core.exceptions.TooManyRequests,\n",
        "            google.api_core.exceptions.DeadlineExceeded\n",
        "        ):\n",
        "          with debug_output:\n",
        "            command_input.description = 'üí§'\n",
        "          time.sleep(10)\n",
        "          continue\n",
        "      try:\n",
        "        return response.text\n",
        "      except ValueError as e:\n",
        "       with debug_output:\n",
        "        print(f'Response {response} led to the error {e}')\n",
        "\n",
        "model = Gemini(system_prompt, gemini_tools)\n",
        "analysis_model = Gemini(scoring_system_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Zzab3ZUEY4-v",
        "outputId": "2fe0c7ad-6ed3-4d04-c839-28139bf7d653"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UI functions"
      ],
      "metadata": {
        "id": "7J_I_PsdlucV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_cursor_waiting():\n",
        "    js_code = \"\"\"\n",
        "    document.querySelector('body').style.cursor = 'wait';\n",
        "    \"\"\"\n",
        "    display(HTML(f\"<script>{js_code}</script>\"))\n",
        "\n",
        "def set_cursor_default():\n",
        "    js_code = \"\"\"\n",
        "    document.querySelector('body').style.cursor = 'default';\n",
        "    \"\"\"\n",
        "    display(HTML(f\"<script>{js_code}</script>\"))\n",
        "\n",
        "def on_submit(widget):\n",
        "    global map_dirty\n",
        "    map_dirty = False\n",
        "    command_input.description = 'üôÇ'\n",
        "    command = widget.value\n",
        "    if not command:\n",
        "      command = 'go on'\n",
        "    with chat_output:\n",
        "      print('> ' + command + '\\n')\n",
        "    if command != 'go on':\n",
        "      with debug_output:\n",
        "        print('> ' + command + '\\n')\n",
        "    widget.value = ''\n",
        "    set_cursor_waiting()\n",
        "    command_input.description = 'ü§î'\n",
        "    response = model.chat(command, temperature=0)\n",
        "    if map_dirty:\n",
        "      command_input.description = 'üôè'\n",
        "    else:\n",
        "      command_input.description = 'üôÇ'\n",
        "    set_cursor_default()\n",
        "    response = response.strip()\n",
        "    if not response:\n",
        "      response = '<EMPTY RESPONSE, HIT ENTER>'\n",
        "    with chat_output:\n",
        "        print(response + '\\n')\n",
        "    command_input.value = ''\n",
        "\n",
        "command_input.on_submit(on_submit)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "y64VbasPY-UP",
        "outputId": "711290b9-9e28-4d10-9c61-6cc3fc194c93"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UI layout"
      ],
      "metadata": {
        "id": "rUahB4melyxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Arrange the chat history and input in a vertical box\n",
        "chat_ui = widgets.VBox([image_widget, chat_output], layout=widgets.Layout(width='400px'))\n",
        "\n",
        "chat_output.layout = widgets.Layout(width='400px')  # Fixed width for the left control\n",
        "Map.layout = widgets.Layout(flex='1 1 auto')\n",
        "\n",
        "table = widgets.HBox([chat_ui, debug_output, Map],  layout=widgets.Layout(align_items='flex-start'))\n",
        "\n",
        "ui = widgets.VBox([table, command_input])\n",
        "\n",
        "# Display the layout\n",
        "display(ui)\n",
        "print('üôÇ = waiting for user input')\n",
        "print('üôè = waiting for user to hit enter after calling set_center()')\n",
        "print('ü§î = thinking')\n",
        "print('üí§ = sleeping due to retries')\n",
        "print('üò° = Gemini recitation error')"
      ],
      "metadata": {
        "id": "5YUIQVyJ8VJc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}